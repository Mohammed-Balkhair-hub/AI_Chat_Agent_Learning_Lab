{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "453cf6f5",
      "metadata": {},
      "source": [
        "# Mistral AI SDK - Learning Notebook\n",
        "\n",
        "This tutorial introduces you to working with the Mistral AI API using the Mistral SDK, progressing from simple API calls to building a CV scoring and retrieval system.\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this tutorial, you will be able to:\n",
        "- Use the Mistral AI API to generate content\n",
        "- Build a CV scoring system that evaluates resumes against job descriptions\n",
        "- Implement RAG-based CV retrieval using vector similarity search\n",
        "- Combine fast retrieval (FAISS) with intelligent re-ranking (Mistral)\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Before starting, make sure you have:\n",
        "- Obtained a Mistral AI API key from [Mistral AI Console](https://console.mistral.ai/)\n",
        "- Installed the required dependencies listed in `pyproject.toml` via `uv sync`\n",
        "- Set up your `.env` file with `MISTRAL_API_KEY=your_key_here`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a85e7ed6",
      "metadata": {},
      "source": [
        "## Part 1: Getting Started with Mistral AI SDK"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19a1f57b",
      "metadata": {},
      "source": [
        "### Import the SDK and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b23be16c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from mistralai import Mistral\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ed75563",
      "metadata": {},
      "source": [
        "### Initialize the Mistral Client\n",
        "\n",
        "The Mistral SDK uses a `Mistral` client object to make requests. The client handles authentication using your API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "41df9e46",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mistral client initialized successfully!\n"
          ]
        }
      ],
      "source": [
        "# Initialize the Mistral client\n",
        "api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"MISTRAL_API_KEY not found in environment. Please set it in .env file.\")\n",
        "\n",
        "client = Mistral(api_key=api_key)\n",
        "print(\"Mistral client initialized successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b51dd670",
      "metadata": {},
      "source": [
        "### Run Your First Prompt\n",
        "\n",
        "Let's start with a simple text generation request. The `mistral-large-latest` model is Mistral's most capable model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f8d2692e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sure! Imagine you have a super-smart robot friend who *loves* to learn‚Äîjust like how you learn new things in school or from your parents.\n",
            "\n",
            "### Here‚Äôs how AI works in simple steps:\n",
            "1. **Learning Like a Sponge** üßΩ\n",
            "   - AI starts by watching or reading *tons* of examples (like pictures, words, or games).\n",
            "   - Example: If you show it 1,000 pictures of cats and dogs, it learns to tell them apart‚Äîjust like you do!\n",
            "\n",
            "2. **Practice Makes Perfect** üéÆ\n",
            "   - The AI plays games or solves puzzles *over and over* to get better (like how you practice soccer or math).\n",
            "   - If it makes a mistake, it says, *\"Oops! Let me try again!\"*\n",
            "\n",
            "3. **Helping You!** ü§ñ\n",
            "   - Once it learns, it can:\n",
            "     - **Answer questions** (like a super-smart encyclopedia).\n",
            "     - **Draw pictures** (like a robot artist).\n",
            "     - **Play games** (and sometimes beat you at them!).\n",
            "     - **Talk to you** (like a chat buddy).\n",
            "\n",
            "### Cool Examples:\n",
            "- **Voice Assistants**: Like Siri or Alexa‚Äîthey listen to your voice and do what you ask (e.g., \"Play my favorite song!\").\n",
            "- **Self-Driving Cars**: AI \"sees\" the road (like you do) and drives safely.\n",
            "- **Video Games**: Enemies in games sometimes use AI to act smart (like hiding or chasing you).\n",
            "\n",
            "### But Remember:\n",
            "- AI isn‚Äôt *alive*‚Äîit‚Äôs just really good at following rules and learning from examples.\n",
            "- It doesn‚Äôt have feelings or dreams (yet!), but it can *pretend* to be friendly.\n",
            "\n",
            "**Fun Fact**: AI is like a parrot ü¶ú‚Äîit repeats what it‚Äôs taught, but it doesn‚Äôt *understand* things the way you do!\n",
            "\n",
            "Want to try teaching an AI? You could show it drawings and say, \"This is a dinosaur!\" and it might learn to draw one too! ü¶ñ‚úèÔ∏è\n",
            "\n",
            "Does that make sense? üòä\n"
          ]
        }
      ],
      "source": [
        "# Simple text generation\n",
        "response = client.chat.complete(\n",
        "    model=\"mistral-large-latest\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Explain AI to me like I'm a kid.\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81e42aa0",
      "metadata": {},
      "source": [
        "The response can be rendered directly as markdown in notebooks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7e5d021f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Sure! Imagine you have a super-smart robot friend who *loves* to learn‚Äîjust like how you learn new things in school or from your parents.\n",
              "\n",
              "### Here‚Äôs how AI works in simple steps:\n",
              "1. **Learning Like a Sponge** üßΩ\n",
              "   - AI starts by watching or reading *tons* of examples (like pictures, words, or games).\n",
              "   - Example: If you show it 1,000 pictures of cats and dogs, it learns to tell them apart‚Äîjust like you do!\n",
              "\n",
              "2. **Practice Makes Perfect** üéÆ\n",
              "   - The AI plays games or solves puzzles *over and over* to get better (like how you practice soccer or math).\n",
              "   - If it makes a mistake, it says, *\"Oops! Let me try again!\"*\n",
              "\n",
              "3. **Helping You!** ü§ñ\n",
              "   - Once it learns, it can:\n",
              "     - **Answer questions** (like a super-smart encyclopedia).\n",
              "     - **Draw pictures** (like a robot artist).\n",
              "     - **Play games** (and sometimes beat you at them!).\n",
              "     - **Talk to you** (like a chat buddy).\n",
              "\n",
              "### Cool Examples:\n",
              "- **Voice Assistants**: Like Siri or Alexa‚Äîthey listen to your voice and do what you ask (e.g., \"Play my favorite song!\").\n",
              "- **Self-Driving Cars**: AI \"sees\" the road (like you do) and drives safely.\n",
              "- **Video Games**: Enemies in games sometimes use AI to act smart (like hiding or chasing you).\n",
              "\n",
              "### But Remember:\n",
              "- AI isn‚Äôt *alive*‚Äîit‚Äôs just really good at following rules and learning from examples.\n",
              "- It doesn‚Äôt have feelings or dreams (yet!), but it can *pretend* to be friendly.\n",
              "\n",
              "**Fun Fact**: AI is like a parrot ü¶ú‚Äîit repeats what it‚Äôs taught, but it doesn‚Äôt *understand* things the way you do!\n",
              "\n",
              "Want to try teaching an AI? You could show it drawings and say, \"This is a dinosaur!\" and it might learn to draw one too! ü¶ñ‚úèÔ∏è\n",
              "\n",
              "Does that make sense? üòä"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display as markdown\n",
        "display(Markdown(response.choices[0].message.content))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a164db77",
      "metadata": {},
      "source": [
        "### Start a Chat Conversation\n",
        "\n",
        "Mistral supports multi-turn conversations where the conversation history is maintained. Each message includes the full conversation context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "737e6ead",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello, Alex! üòä It's nice to meet you! How can I assist you today? Whether you have questions, need help with something, or just want to chat, I'm here for it. üöÄ\n"
          ]
        }
      ],
      "source": [
        "# Start a conversation\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Hello! My name is Alex.\"}\n",
        "]\n",
        "\n",
        "response = client.chat.complete(\n",
        "    model=\"mistral-large-latest\",\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "98a57c06",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your name is **Alex**‚Äînice to officially meet you again! üòÑ Let me know if you'd like me to remember anything else about you.\n"
          ]
        }
      ],
      "source": [
        "# Continue the conversation - add previous messages to maintain context\n",
        "messages.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
        "messages.append({\"role\": \"user\", \"content\": \"What is my name?\"})\n",
        "\n",
        "response = client.chat.complete(\n",
        "    model=\"mistral-large-latest\",\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3943a5a4",
      "metadata": {},
      "source": [
        "### Control Generation Parameters\n",
        "\n",
        "You can control the model's behavior using parameters like `temperature` and `max_tokens`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cd4fade9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Debugging at dawn‚Äî\n",
            "a missing semicolon\n",
            "breaks the whole world.\n"
          ]
        }
      ],
      "source": [
        "# Example with different parameters\n",
        "response = client.chat.complete(\n",
        "    model=\"mistral-large-latest\",\n",
        "    temperature=0.7,  # Control randomness (0.0 = deterministic, 1.0 = creative)\n",
        "    max_tokens=500,  # Limit response length\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Write a short haiku about programming.\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "646376bf",
      "metadata": {},
      "source": [
        "## Part 2: CV Scoring Project\n",
        "\n",
        "In this section, we'll build a system that scores a CV against a job description using Mistral's reasoning capabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ffde5bf",
      "metadata": {},
      "source": [
        "### Load a Sample CV\n",
        "\n",
        "Let's load a CV from the CVs folder to use for scoring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a4cee3c5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV loaded: 2007 characters\n",
            "\n",
            "First 500 characters:\n",
            "# Ahmed Al-Otaibi\n",
            "**AI Engineer**\n",
            "\n",
            "Riyadh, Saudi Arabia | +966500000000 | ahmed.otaibi@email.com\n",
            "[linkedin.com/in/ahmed-ai] | [github.com/ahmed-code]\n",
            "\n",
            "---\n",
            "\n",
            "## Skills\n",
            "\n",
            "* **Programming Languages:** Python, C++, SQL.\n",
            "* **Machine & Deep Learning:** PyTorch, TensorFlow, Scikit-learn, Keras, Hugging Face (Transformers).\n",
            "* **Deployment & Cloud Computing:** Docker, Kubernetes, AWS (SageMaker), FastAPI, CI/CD Pipelines.\n",
            "* **Specializations:** NLP (Natural Language Processing), Computer Vision, Generative\n"
          ]
        }
      ],
      "source": [
        "# Load a sample CV\n",
        "cv_path = \"../CVs/Topic_1/01_en.md\"\n",
        "\n",
        "with open(cv_path, 'r', encoding='utf-8') as f:\n",
        "    cv_content = f.read()\n",
        "\n",
        "print(f\"CV loaded: {len(cv_content)} characters\")\n",
        "print(\"\\nFirst 500 characters:\")\n",
        "print(cv_content[:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9c33fbd",
      "metadata": {},
      "source": [
        "### Define a Job Description\n",
        "\n",
        "Create a sample job description to score the CV against."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a3287087",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "AI Engineer Position\n",
            "\n",
            "We are looking for an experienced AI Engineer to join our team.\n",
            "\n",
            "Requirements:\n",
            "- Strong experience with Python and machine learning frameworks (PyTorch, TensorFlow)\n",
            "- Experience deploying ML models to production (Docker, FastAPI, AWS)\n",
            "- Background in NLP or Computer Vision\n",
            "- Experience with Hugging Face transformers\n",
            "- Strong problem-solving skills and ability to work in a team\n",
            "\n",
            "Nice to have:\n",
            "- Experience with Kubernetes\n",
            "- Knowledge of model optimization techniques (quantization, pruning)\n",
            "- Experience with recommendation systems\n",
            "\n"
          ]
        }
      ],
      "source": [
        "job_description = \"\"\"\n",
        "AI Engineer Position\n",
        "\n",
        "We are looking for an experienced AI Engineer to join our team.\n",
        "\n",
        "Requirements:\n",
        "- Strong experience with Python and machine learning frameworks (PyTorch, TensorFlow)\n",
        "- Experience deploying ML models to production (Docker, FastAPI, AWS)\n",
        "- Background in NLP or Computer Vision\n",
        "- Experience with Hugging Face transformers\n",
        "- Strong problem-solving skills and ability to work in a team\n",
        "\n",
        "Nice to have:\n",
        "- Experience with Kubernetes\n",
        "- Knowledge of model optimization techniques (quantization, pruning)\n",
        "- Experience with recommendation systems\n",
        "\"\"\"\n",
        "\n",
        "print(job_description)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c9a7626",
      "metadata": {},
      "source": [
        "### Create Scoring Prompt\n",
        "\n",
        "Build a prompt that asks Mistral to score the CV against the job description and provide detailed reasoning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "380fee18",
      "metadata": {},
      "outputs": [],
      "source": [
        "scoring_prompt = f\"\"\"You are an expert recruiter evaluating a CV against a job description.\n",
        "\n",
        "Job Description:\n",
        "{job_description}\n",
        "\n",
        "CV:\n",
        "{cv_content}\n",
        "\n",
        "Please evaluate this CV and provide:\n",
        "1. An overall match score from 0-100\n",
        "2. Detailed reasoning for the score\n",
        "3. Key strengths that match the job requirements\n",
        "4. Areas where the candidate falls short\n",
        "5. Specific examples from the CV that support your evaluation\n",
        "\n",
        "Format your response as a structured evaluation.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7906d38a",
      "metadata": {},
      "source": [
        "### Call Mistral API to Score the CV\n",
        "\n",
        "Now let's send the prompt to Mistral and get the scoring results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "cecf8155",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### **Structured Evaluation of Ahmed Al-Otaibi‚Äôs CV Against the AI Engineer Job Description**\n",
            "\n",
            "---\n",
            "\n",
            "### **1. Overall Match Score: 92/100**\n",
            "**Rationale:** Ahmed‚Äôs CV demonstrates a **strong alignment** with the job requirements, covering nearly all mandatory and several \"nice-to-have\" skills. His experience in **NLP, Computer Vision, model deployment, and optimization** directly addresses the core needs of the role. Minor gaps (e.g., depth in recommendation systems) prevent a perfect score.\n",
            "\n",
            "---\n",
            "\n",
            "### **2. Detailed Reasoning for the Score**\n",
            "\n",
            "#### **A. Mandatory Requirements (Weight: 70%)**\n",
            "| **Requirement**               | **Match (0-10)** | **Supporting Evidence**                                                                 | **Score** |\n",
            "|-------------------------------|------------------|----------------------------------------------------------------------------------------|-----------|\n",
            "| **Python + ML Frameworks**    | 10/10            | Lists PyTorch, TensorFlow, Keras, Scikit-learn; projects use PyTorch (AraBERT) and TensorFlow (YOLOv8). | 10        |\n",
            "| **ML Model Deployment**       | 10/10            | Deployed models with **Docker + FastAPI** (50K daily requests); AWS SageMaker experience. | 10        |\n",
            "| **NLP/Computer Vision**       | 10/10            | **NLP:** AraBERT fine-tuning (94% accuracy). **CV:** YOLOv8 defect detection (20% FPR reduction). | 10        |\n",
            "| **Hugging Face Transformers** | 10/10            | Explicitly mentions Hugging Face; used AraBERT (a Hugging Face model) in a project.    | 10        |\n",
            "| **Problem-Solving/Teamwork**  | 9/10             | Projects show **quantifiable impact** (e.g., 40% latency improvement, 15% user engagement). Teamwork implied by collaborative projects. | 9         |\n",
            "| **Total (Mandatory)**         | **49/50**        | **Weighted Score: 68.6/70**                                                              |           |\n",
            "\n",
            "#### **B. Nice-to-Have Requirements (Weight: 30%)**\n",
            "| **Requirement**               | **Match (0-10)** | **Supporting Evidence**                                                                 | **Score** |\n",
            "|-------------------------------|------------------|----------------------------------------------------------------------------------------|-----------|\n",
            "| **Kubernetes**                | 10/10            | Lists Kubernetes under **Deployment & Cloud Computing**; likely used in production at FutureTech. | 10        |\n",
            "| **Model Optimization**        | 10/10            | **Quantization** mentioned in CV (40% latency improvement).                            | 10        |\n",
            "| **Recommendation Systems**    | 7/10             | Built a **Recommendation Engine** (15% user engagement boost), but lacks details on scale/complexity. | 7         |\n",
            "| **Total (Nice-to-Have)**      | **27/30**        | **Weighted Score: 27/30**                                                               |           |\n",
            "\n",
            "#### **C. Deductions (Minor Gaps)**\n",
            "- **Recommendation Systems:** While Ahmed has experience, the CV doesn‚Äôt specify if the system used **collaborative filtering, deep learning (e.g., Two-Tower models), or hybrid approaches**, which are common in production.\n",
            "- **AWS Depth:** AWS SageMaker is mentioned, but no details on **specific services** (e.g., Lambda, ECS, EKS) or **cost optimization**.\n",
            "- **Teamwork:** The CV implies collaboration but lacks **explicit examples** of cross-functional work (e.g., with data engineers, product teams).\n",
            "\n",
            "**Total Deductions: -8/100**\n",
            "\n",
            "---\n",
            "\n",
            "### **3. Key Strengths Matching the Job Requirements**\n",
            "1. **End-to-End ML Expertise:**\n",
            "   - **Training:** Fine-tuned AraBERT (NLP) and YOLOv8 (CV) with **state-of-the-art results**.\n",
            "   - **Deployment:** Docker + FastAPI in production (50K daily requests); Kubernetes experience.\n",
            "   - **Optimization:** Quantization (40% latency improvement) and model pruning (implied by \"reducing model size\").\n",
            "\n",
            "2. **Specialization in NLP/CV:**\n",
            "   - **NLP:** AraBERT project (dialect classification) with **94% accuracy** (12% improvement over baselines).\n",
            "   - **CV:** YOLOv8 for real-time defect detection (20% FPR reduction).\n",
            "\n",
            "3. **Hugging Face + Modern Tools:**\n",
            "   - Direct experience with **Hugging Face Transformers** (AraBERT) and **PyTorch/TensorFlow**.\n",
            "\n",
            "4. **Business Impact:**\n",
            "   - **Quantifiable results** in every project/experience (e.g., 15% user engagement, 8% inventory waste reduction).\n",
            "\n",
            "5. **Cloud + DevOps:**\n",
            "   - AWS (SageMaker), Docker, Kubernetes, and CI/CD pipelines.\n",
            "\n",
            "---\n",
            "\n",
            "### **4. Areas Where the Candidate Falls Short**\n",
            "1. **Recommendation Systems:**\n",
            "   - The CV mentions a **Recommendation Engine**, but lacks details on:\n",
            "     - **Approach** (collaborative filtering, content-based, hybrid, or deep learning).\n",
            "     - **Scale** (e.g., number of users/items, A/B test results).\n",
            "     - **Tools** (e.g., TensorFlow Recommenders, LightFM).\n",
            "\n",
            "2. **AWS Specifics:**\n",
            "   - While AWS is listed, the CV doesn‚Äôt specify **which services** were used (e.g., EKS for Kubernetes, Lambda for serverless, or S3 for storage).\n",
            "\n",
            "3. **Team Collaboration:**\n",
            "   - No explicit mention of **working with non-technical teams** (e.g., product managers, designers) or **cross-functional projects**.\n",
            "\n",
            "4. **Model Explainability:**\n",
            "   - No mention of **SHAP, LIME, or other explainability tools**, which are increasingly important in production ML.\n",
            "\n",
            "---\n",
            "\n",
            "### **5. Specific Examples Supporting the Evaluation**\n",
            "#### **Strengths:**\n",
            "- **NLP Project (AraBERT):**\n",
            "  > *\"Fine-tuned the AraBERT model on a dataset of over 100,000 tweets for dialect classification. Achieved 94% accuracy, outperforming baseline models by 12%.\"*\n",
            "  - **Why it matches:** Demonstrates **Hugging Face Transformers** and **NLP expertise** with **quantifiable impact**.\n",
            "\n",
            "- **Deployment (FutureTech):**\n",
            "  > *\"Deployed deep learning models to a production environment using Docker and FastAPI to serve over 50,000 requests daily.\"*\n",
            "  - **Why it matches:** Directly addresses **Docker + FastAPI** requirement with **scalability evidence**.\n",
            "\n",
            "- **Optimization (Quantization):**\n",
            "  > *\"Improved API latency by 40% by optimizing the model architecture and reducing its size (Quantization).\"*\n",
            "  - **Why it matches:** Shows **model optimization** (a \"nice-to-have\") with **measurable results**.\n",
            "\n",
            "#### **Gaps:**\n",
            "- **Recommendation Engine (FutureTech):**\n",
            "  > *\"Designed a Recommendation Engine that contributed to a 15% increase in user engagement during the first quarter.\"*\n",
            "  - **Why it‚Äôs a gap:** No details on **algorithm, scale, or tools used**.\n",
            "\n",
            "- **AWS Usage:**\n",
            "  - **Missing:** Specific AWS services (e.g., \"Used AWS EKS for Kubernetes orchestration\" or \"Deployed models on SageMaker Endpoints\").\n",
            "\n",
            "---\n",
            "\n",
            "### **6. Final Recommendations**\n",
            "- **For the Hiring Team:**\n",
            "  - **Strong hire** with minimal risk. Ahmed‚Äôs **technical skills, deployment experience, and business impact** align closely with the role.\n",
            "  - **Interview focus areas:**\n",
            "    - Dive deeper into the **Recommendation Engine** (approach, challenges, scalability).\n",
            "    - Assess **collaboration skills** (e.g., \"Tell me about a time you worked with a non-technical team\").\n",
            "    - Explore **AWS expertise** (e.g., \"Which AWS services have you used for model deployment?\").\n",
            "\n",
            "- **For the Candidate:**\n",
            "  - **Improve CV by:**\n",
            "    - Adding **more details** on the Recommendation Engine (e.g., \"Built a hybrid recommender using LightFM and TensorFlow, serving 100K+ users\").\n",
            "    - Specifying **AWS services** (e.g., \"Deployed models on SageMaker with Lambda for inference\").\n",
            "    - Including **teamwork examples** (e.g., \"Collaborated with data engineers to optimize feature pipelines\").\n",
            "\n",
            "---\n",
            "\n",
            "### **Summary**\n",
            "| **Category**          | **Score** | **Notes**                                                                 |\n",
            "|-----------------------|-----------|---------------------------------------------------------------------------|\n",
            "| **Mandatory Skills**  | 98%       | Covers all requirements with strong evidence.                            |\n",
            "| **Nice-to-Have**      | 90%       | Kubernetes and optimization are strengths; recommendation systems need depth. |\n",
            "| **Business Impact**   | 100%      | Every project/experience includes quantifiable results.                  |\n",
            "| **Gaps**              | 8%        | Minor: recommendation systems, AWS specifics, teamwork details.          |\n",
            "| **Overall**           | **92/100**| **Top-tier candidate** with room for minor improvements in CV clarity.   |\n"
          ]
        }
      ],
      "source": [
        "# Get scoring from Mistral\n",
        "response = client.chat.complete(\n",
        "    model=\"mistral-large-latest\",\n",
        "    max_tokens=2048,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": scoring_prompt}\n",
        "    ]\n",
        ")\n",
        "\n",
        "scoring_result = response.choices[0].message.content\n",
        "print(scoring_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0444771e",
      "metadata": {},
      "source": [
        "### Display Results as Markdown\n",
        "\n",
        "Let's render the scoring results nicely:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cdd56b9a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "### **Structured Evaluation of Ahmed Al-Otaibi‚Äôs CV Against the AI Engineer Job Description**\n",
              "\n",
              "---\n",
              "\n",
              "### **1. Overall Match Score: 92/100**\n",
              "**Rationale:** Ahmed‚Äôs CV demonstrates a **strong alignment** with the job requirements, covering nearly all mandatory and several \"nice-to-have\" skills. His experience in **NLP, Computer Vision, model deployment, and optimization** directly addresses the core needs of the role. Minor gaps (e.g., depth in recommendation systems) prevent a perfect score.\n",
              "\n",
              "---\n",
              "\n",
              "### **2. Detailed Reasoning for the Score**\n",
              "\n",
              "#### **A. Mandatory Requirements (Weight: 70%)**\n",
              "| **Requirement**               | **Match (0-10)** | **Supporting Evidence**                                                                 | **Score** |\n",
              "|-------------------------------|------------------|----------------------------------------------------------------------------------------|-----------|\n",
              "| **Python + ML Frameworks**    | 10/10            | Lists PyTorch, TensorFlow, Keras, Scikit-learn; projects use PyTorch (AraBERT) and TensorFlow (YOLOv8). | 10        |\n",
              "| **ML Model Deployment**       | 10/10            | Deployed models with **Docker + FastAPI** (50K daily requests); AWS SageMaker experience. | 10        |\n",
              "| **NLP/Computer Vision**       | 10/10            | **NLP:** AraBERT fine-tuning (94% accuracy). **CV:** YOLOv8 defect detection (20% FPR reduction). | 10        |\n",
              "| **Hugging Face Transformers** | 10/10            | Explicitly mentions Hugging Face; used AraBERT (a Hugging Face model) in a project.    | 10        |\n",
              "| **Problem-Solving/Teamwork**  | 9/10             | Projects show **quantifiable impact** (e.g., 40% latency improvement, 15% user engagement). Teamwork implied by collaborative projects. | 9         |\n",
              "| **Total (Mandatory)**         | **49/50**        | **Weighted Score: 68.6/70**                                                              |           |\n",
              "\n",
              "#### **B. Nice-to-Have Requirements (Weight: 30%)**\n",
              "| **Requirement**               | **Match (0-10)** | **Supporting Evidence**                                                                 | **Score** |\n",
              "|-------------------------------|------------------|----------------------------------------------------------------------------------------|-----------|\n",
              "| **Kubernetes**                | 10/10            | Lists Kubernetes under **Deployment & Cloud Computing**; likely used in production at FutureTech. | 10        |\n",
              "| **Model Optimization**        | 10/10            | **Quantization** mentioned in CV (40% latency improvement).                            | 10        |\n",
              "| **Recommendation Systems**    | 7/10             | Built a **Recommendation Engine** (15% user engagement boost), but lacks details on scale/complexity. | 7         |\n",
              "| **Total (Nice-to-Have)**      | **27/30**        | **Weighted Score: 27/30**                                                               |           |\n",
              "\n",
              "#### **C. Deductions (Minor Gaps)**\n",
              "- **Recommendation Systems:** While Ahmed has experience, the CV doesn‚Äôt specify if the system used **collaborative filtering, deep learning (e.g., Two-Tower models), or hybrid approaches**, which are common in production.\n",
              "- **AWS Depth:** AWS SageMaker is mentioned, but no details on **specific services** (e.g., Lambda, ECS, EKS) or **cost optimization**.\n",
              "- **Teamwork:** The CV implies collaboration but lacks **explicit examples** of cross-functional work (e.g., with data engineers, product teams).\n",
              "\n",
              "**Total Deductions: -8/100**\n",
              "\n",
              "---\n",
              "\n",
              "### **3. Key Strengths Matching the Job Requirements**\n",
              "1. **End-to-End ML Expertise:**\n",
              "   - **Training:** Fine-tuned AraBERT (NLP) and YOLOv8 (CV) with **state-of-the-art results**.\n",
              "   - **Deployment:** Docker + FastAPI in production (50K daily requests); Kubernetes experience.\n",
              "   - **Optimization:** Quantization (40% latency improvement) and model pruning (implied by \"reducing model size\").\n",
              "\n",
              "2. **Specialization in NLP/CV:**\n",
              "   - **NLP:** AraBERT project (dialect classification) with **94% accuracy** (12% improvement over baselines).\n",
              "   - **CV:** YOLOv8 for real-time defect detection (20% FPR reduction).\n",
              "\n",
              "3. **Hugging Face + Modern Tools:**\n",
              "   - Direct experience with **Hugging Face Transformers** (AraBERT) and **PyTorch/TensorFlow**.\n",
              "\n",
              "4. **Business Impact:**\n",
              "   - **Quantifiable results** in every project/experience (e.g., 15% user engagement, 8% inventory waste reduction).\n",
              "\n",
              "5. **Cloud + DevOps:**\n",
              "   - AWS (SageMaker), Docker, Kubernetes, and CI/CD pipelines.\n",
              "\n",
              "---\n",
              "\n",
              "### **4. Areas Where the Candidate Falls Short**\n",
              "1. **Recommendation Systems:**\n",
              "   - The CV mentions a **Recommendation Engine**, but lacks details on:\n",
              "     - **Approach** (collaborative filtering, content-based, hybrid, or deep learning).\n",
              "     - **Scale** (e.g., number of users/items, A/B test results).\n",
              "     - **Tools** (e.g., TensorFlow Recommenders, LightFM).\n",
              "\n",
              "2. **AWS Specifics:**\n",
              "   - While AWS is listed, the CV doesn‚Äôt specify **which services** were used (e.g., EKS for Kubernetes, Lambda for serverless, or S3 for storage).\n",
              "\n",
              "3. **Team Collaboration:**\n",
              "   - No explicit mention of **working with non-technical teams** (e.g., product managers, designers) or **cross-functional projects**.\n",
              "\n",
              "4. **Model Explainability:**\n",
              "   - No mention of **SHAP, LIME, or other explainability tools**, which are increasingly important in production ML.\n",
              "\n",
              "---\n",
              "\n",
              "### **5. Specific Examples Supporting the Evaluation**\n",
              "#### **Strengths:**\n",
              "- **NLP Project (AraBERT):**\n",
              "  > *\"Fine-tuned the AraBERT model on a dataset of over 100,000 tweets for dialect classification. Achieved 94% accuracy, outperforming baseline models by 12%.\"*\n",
              "  - **Why it matches:** Demonstrates **Hugging Face Transformers** and **NLP expertise** with **quantifiable impact**.\n",
              "\n",
              "- **Deployment (FutureTech):**\n",
              "  > *\"Deployed deep learning models to a production environment using Docker and FastAPI to serve over 50,000 requests daily.\"*\n",
              "  - **Why it matches:** Directly addresses **Docker + FastAPI** requirement with **scalability evidence**.\n",
              "\n",
              "- **Optimization (Quantization):**\n",
              "  > *\"Improved API latency by 40% by optimizing the model architecture and reducing its size (Quantization).\"*\n",
              "  - **Why it matches:** Shows **model optimization** (a \"nice-to-have\") with **measurable results**.\n",
              "\n",
              "#### **Gaps:**\n",
              "- **Recommendation Engine (FutureTech):**\n",
              "  > *\"Designed a Recommendation Engine that contributed to a 15% increase in user engagement during the first quarter.\"*\n",
              "  - **Why it‚Äôs a gap:** No details on **algorithm, scale, or tools used**.\n",
              "\n",
              "- **AWS Usage:**\n",
              "  - **Missing:** Specific AWS services (e.g., \"Used AWS EKS for Kubernetes orchestration\" or \"Deployed models on SageMaker Endpoints\").\n",
              "\n",
              "---\n",
              "\n",
              "### **6. Final Recommendations**\n",
              "- **For the Hiring Team:**\n",
              "  - **Strong hire** with minimal risk. Ahmed‚Äôs **technical skills, deployment experience, and business impact** align closely with the role.\n",
              "  - **Interview focus areas:**\n",
              "    - Dive deeper into the **Recommendation Engine** (approach, challenges, scalability).\n",
              "    - Assess **collaboration skills** (e.g., \"Tell me about a time you worked with a non-technical team\").\n",
              "    - Explore **AWS expertise** (e.g., \"Which AWS services have you used for model deployment?\").\n",
              "\n",
              "- **For the Candidate:**\n",
              "  - **Improve CV by:**\n",
              "    - Adding **more details** on the Recommendation Engine (e.g., \"Built a hybrid recommender using LightFM and TensorFlow, serving 100K+ users\").\n",
              "    - Specifying **AWS services** (e.g., \"Deployed models on SageMaker with Lambda for inference\").\n",
              "    - Including **teamwork examples** (e.g., \"Collaborated with data engineers to optimize feature pipelines\").\n",
              "\n",
              "---\n",
              "\n",
              "### **Summary**\n",
              "| **Category**          | **Score** | **Notes**                                                                 |\n",
              "|-----------------------|-----------|---------------------------------------------------------------------------|\n",
              "| **Mandatory Skills**  | 98%       | Covers all requirements with strong evidence.                            |\n",
              "| **Nice-to-Have**      | 90%       | Kubernetes and optimization are strengths; recommendation systems need depth. |\n",
              "| **Business Impact**   | 100%      | Every project/experience includes quantifiable results.                  |\n",
              "| **Gaps**              | 8%        | Minor: recommendation systems, AWS specifics, teamwork details.          |\n",
              "| **Overall**           | **92/100**| **Top-tier candidate** with room for minor improvements in CV clarity.   |"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display formatted results\n",
        "display(Markdown(scoring_result))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e93e2621",
      "metadata": {},
      "source": [
        "### Extract Structured Output (Optional)\n",
        "\n",
        "If you want to extract specific information like the score, you can parse the response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2432239a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted Score: 92/100\n"
          ]
        }
      ],
      "source": [
        "# Simple extraction of score (if mentioned in response)\n",
        "import re\n",
        "\n",
        "# Try to extract score from the response\n",
        "score_match = re.search(r'(\\d+)\\s*(?:out of 100|/100|%)', scoring_result, re.IGNORECASE)\n",
        "if score_match:\n",
        "    extracted_score = score_match.group(1)\n",
        "    print(f\"Extracted Score: {extracted_score}/100\")\n",
        "else:\n",
        "    print(\"Score not found in expected format. Check the full response above.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9810ce5",
      "metadata": {},
      "source": [
        "## Part 3: RAG-Based CV Retrieval\n",
        "\n",
        "In this section, we'll build a RAG (Retrieval-Augmented Generation) system that:\n",
        "1. Uses FAISS for fast similarity search across multiple CVs\n",
        "2. Uses Mistral for intelligent re-ranking and scoring\n",
        "\n",
        "**Hybrid Approach:** We combine the speed of vector similarity search (FAISS) with Mistral's reasoning capabilities for the best of both worlds."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0da673aa",
      "metadata": {},
      "source": [
        "### Load All CV Files\n",
        "\n",
        "First, let's load all CV markdown files from the CVs folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99dd8690",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 40 CV files\n",
            "\n",
            "Loaded 40 CVs\n",
            "Sample CV names: ['38', '18', '08', '19', '09']\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "from pathlib import Path\n",
        "\n",
        "# Find all markdown CV files\n",
        "cv_base_path = Path(\"../datasets/CVs\")\n",
        "cv_files = list(cv_base_path.rglob(\"*.md\"))\n",
        "\n",
        "print(f\"Found {len(cv_files)} CV files\")\n",
        "\n",
        "# Load all CVs\n",
        "cv_data = []\n",
        "for cv_file in cv_files:\n",
        "    with open(cv_file, 'r', encoding='utf-8') as f:\n",
        "        content = f.read()\n",
        "        cv_data.append({\n",
        "            'path': str(cv_file),\n",
        "            'name': cv_file.stem,\n",
        "            'content': content\n",
        "        })\n",
        "\n",
        "print(f\"\\nLoaded {len(cv_data)} CVs\")\n",
        "print(f\"Sample CV names: {[cv['name'] for cv in cv_data[:5]]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6536963c",
      "metadata": {},
      "source": [
        "### Initialize Sentence Transformer Model\n",
        "\n",
        "**Important:** Despite the name \"sentence-transformers\", this library works with full documents! It processes entire CVs (even 1000+ words) and produces a single fixed-size embedding vector (e.g., 384 dimensions) that captures the semantic meaning of the whole document. This is standard practice for document similarity tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "98bdc335",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f32a06de282d4907ae0e4ba947bf1dd3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29a11ada2703432198c5c983ee9fd684",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "132e48adf2314fcc952e78b92cb93a55",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c16a51d9cae47419c1a06ed6cbf87c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07f88b8447544ed3b53f788a1d82f9e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73910dee30234a37a05d6d28212f4db7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5869189aaafe4a6b8ea4c225295e62a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ab3e233f1e24edcb94c242efee452c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb78084f007d498f87a4394f2e0c2e9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1e5b310253f4cfd94c47c33bc754e44",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3291b36a7f8a48829a8249466a277edf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence transformer model loaded!\n",
            "Model will produce embeddings of dimension: 384\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Initialize the model - works with full documents, not just sentences\n",
        "# This model produces 384-dimensional embeddings\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "print(\"Sentence transformer model loaded!\")\n",
        "print(f\"Model will produce embeddings of dimension: {model.get_sentence_embedding_dimension()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9322a9d9",
      "metadata": {},
      "source": [
        "### Generate Embeddings for All CVs\n",
        "\n",
        "Each full CV (entire document) will become one embedding vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "69a73321",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating embeddings for all CVs...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02c480fe2e934d1bb3e65aeb748f0338",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Embeddings shape: (40, 384)\n",
            "Number of CVs: 40\n",
            "Embedding dimension: 384\n"
          ]
        }
      ],
      "source": [
        "# Extract CV texts\n",
        "cv_texts = [cv['content'] for cv in cv_data]\n",
        "\n",
        "# Generate embeddings - each CV becomes one vector\n",
        "# Shape will be (num_cvs, 384) - one 384-dimensional vector per CV\n",
        "print(\"Generating embeddings for all CVs...\")\n",
        "cv_embeddings = model.encode(cv_texts, show_progress_bar=True)\n",
        "\n",
        "print(f\"\\nEmbeddings shape: {cv_embeddings.shape}\")\n",
        "print(f\"Number of CVs: {len(cv_data)}\")\n",
        "print(f\"Embedding dimension: {cv_embeddings.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "729b22f1",
      "metadata": {},
      "source": [
        "### Generate Embedding for Job Description\n",
        "\n",
        "Now let's create an embedding for the job description so we can find similar CVs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "78d9badd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Job description embedding shape: (1, 384)\n",
            "Job description embedded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Generate embedding for job description\n",
        "job_embedding = model.encode([job_description])\n",
        "\n",
        "print(f\"Job description embedding shape: {job_embedding.shape}\")\n",
        "print(\"Job description embedded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d8683e5a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAISS index created with 40 CVs\n",
            "Index dimension: 384\n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Get the dimension of embeddings\n",
        "dimension = cv_embeddings.shape[1]\n",
        "\n",
        "# Create FAISS index using L2 (Euclidean) distance\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "# Convert to float32 (required by FAISS) and add embeddings\n",
        "index.add(cv_embeddings.astype('float32'))\n",
        "\n",
        "print(f\"FAISS index created with {index.ntotal} CVs\")\n",
        "print(f\"Index dimension: {dimension}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "507006e7",
      "metadata": {},
      "source": [
        "### Search for Top-K Most Relevant CVs\n",
        "\n",
        "Now let's search for the CVs most similar to the job description using FAISS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "85c200cb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 5 most similar CVs found:\n",
            "\n",
            "Distances (lower is more similar): [0.7747874 0.8298741 0.9185155 1.0286415 1.032957 ]\n",
            "Indices: [24 39 37 36 25]\n"
          ]
        }
      ],
      "source": [
        "# Number of top CVs to retrieve\n",
        "k = 5\n",
        "\n",
        "# Search for top-k similar CVs\n",
        "# FAISS returns distances and indices\n",
        "distances, indices = index.search(job_embedding.astype('float32'), k)\n",
        "\n",
        "print(f\"Top {k} most similar CVs found:\")\n",
        "print(f\"\\nDistances (lower is more similar): {distances[0]}\")\n",
        "print(f\"Indices: {indices[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9701ce7",
      "metadata": {},
      "source": [
        "### Display Retrieved CVs with Similarity Scores\n",
        "\n",
        "Let's see which CVs were retrieved and their similarity scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "b402b787",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "\n",
            "1. CV: 01_en\n",
            "   Path: ../CVs/Topic_1/01_en.md\n",
            "   Similarity Distance: 0.7748 (lower = more similar)\n",
            "   Preview: # Ahmed Al-Otaibi\n",
            "**AI Engineer**\n",
            "\n",
            "Riyadh, Saudi Arabia | +966500000000 | ahmed.otaibi@email.com\n",
            "[linkedin.com/in/ahmed-ai] | [github.com/ahmed-code]\n",
            "\n",
            "---\n",
            "\n",
            "## Skills\n",
            "\n",
            "* **Programming Languages:** Pyth...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "2. CV: 11\n",
            "   Path: ../CVs/Topic_1/11.md\n",
            "   Similarity Distance: 0.8299 (lower = more similar)\n",
            "   Preview: # Nasser Al-Khaldi\n",
            "**AI Engineer**\n",
            "\n",
            "Riyadh, Saudi Arabia | +966511111111 | nasser.khaldi@email.com\n",
            "[linkedin.com/in/nasser-ai] | [github.com/nasser-code]\n",
            "\n",
            "---\n",
            "\n",
            "## Skills\n",
            "\n",
            "* **Programming Languages:** ...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "3. CV: 21\n",
            "   Path: ../CVs/Topic_1/21.md\n",
            "   Similarity Distance: 0.9185 (lower = more similar)\n",
            "   Preview: # Yasmin Al-Jassim\n",
            "**AI Engineer**\n",
            "\n",
            "Manama, Bahrain | +97334567890 | yasmin.jassim@email.com\n",
            "[linkedin.com/in/yasmin-ai] | [github.com/yasmin-code]\n",
            "\n",
            "---\n",
            "\n",
            "## Skills\n",
            "\n",
            "* **Programming Languages:** Python...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "4. CV: 15\n",
            "   Path: ../CVs/Topic_1/15.md\n",
            "   Similarity Distance: 1.0286 (lower = more similar)\n",
            "   Preview: # Sultan Al-Fahim\n",
            "**MLOps Engineer**\n",
            "\n",
            "Dubai, UAE | +971561111111 | sultan.fahim@email.com\n",
            "[linkedin.com/in/sultan-mlops] | [github.com/sultan-ops]\n",
            "\n",
            "---\n",
            "\n",
            "## Skills\n",
            "\n",
            "* **CI/CD & Automation:** Jenkins, G...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "5. CV: 29\n",
            "   Path: ../CVs/Topic_1/29.md\n",
            "   Similarity Distance: 1.0330 (lower = more similar)\n",
            "   Preview: # Faisal Al-Qahtani\n",
            "**MLOps Engineer**\n",
            "\n",
            "Doha, Qatar | +97477654321 | faisal.qahtani@email.com\n",
            "[linkedin.com/in/faisal-mlops] | [github.com/faisal-q]\n",
            "\n",
            "---\n",
            "\n",
            "## Skills\n",
            "\n",
            "* **Infrastructure as Code:** Terr...\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Display retrieved CVs\n",
        "print(\"=\" * 80)\n",
        "for i, (idx, distance) in enumerate(zip(indices[0], distances[0]), 1):\n",
        "    cv = cv_data[idx]\n",
        "    print(f\"\\n{i}. CV: {cv['name']}\")\n",
        "    print(f\"   Path: {cv['path']}\")\n",
        "    print(f\"   Similarity Distance: {distance:.4f} (lower = more similar)\")\n",
        "    print(f\"   Preview: {cv['content'][:200]}...\")\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "065340ee",
      "metadata": {},
      "source": [
        "### Use Mistral to Re-rank and Score Top Candidates\n",
        "\n",
        "Now let's use Mistral's reasoning capabilities to intelligently re-rank and score the top candidates. This combines fast retrieval (FAISS) with intelligent evaluation (Mistral)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "2e32c688",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare CV summaries for Mistral\n",
        "retrieved_cvs = []\n",
        "for idx in indices[0]:\n",
        "    cv = cv_data[idx]\n",
        "    retrieved_cvs.append({\n",
        "        'name': cv['name'],\n",
        "        'content': cv['content'][:2000]  # Limit length for Mistral context\n",
        "    })\n",
        "\n",
        "# Create prompt for Mistral to re-rank\n",
        "rerank_prompt = f\"\"\"You are an expert recruiter. I've retrieved {len(retrieved_cvs)} CVs that are similar to this job description:\n",
        "\n",
        "Job Description:\n",
        "{job_description}\n",
        "\n",
        "Here are the retrieved CVs:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "for i, cv in enumerate(retrieved_cvs, 1):\n",
        "    rerank_prompt += f\"\"\"\n",
        "CV {i} - {cv['name']}:\n",
        "{cv['content']}\n",
        "---\n",
        "\"\"\"\n",
        "\n",
        "rerank_prompt += \"\"\"\n",
        "Please:\n",
        "1. Rank these CVs from best to worst match for the job description\n",
        "2. Provide a score (0-100) for each CV\n",
        "3. Give brief reasoning for each ranking\n",
        "4. Highlight the top 3 candidates\n",
        "\n",
        "Format your response clearly with rankings, scores, and reasoning.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "10e3e5e0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here‚Äôs the ranked evaluation of the CVs based on the **AI Engineer** job description, with scores (0-100), reasoning, and highlights for the top 3 candidates:\n",
            "\n",
            "---\n",
            "\n",
            "### **Ranking & Scores**\n",
            "| Rank | CV       | Name               | Score | Key Strengths                                                                 | Gaps                                                                 |\n",
            "|------|----------|--------------------|-------|-------------------------------------------------------------------------------|----------------------------------------------------------------------|\n",
            "| 1    | **01_en**| Ahmed Al-Otaibi    | **95**  | Strong Python, PyTorch/TensorFlow, NLP/CV, Hugging Face, Docker/FastAPI/AWS, model optimization, recommendation systems. | Limited Kubernetes experience (but has Docker/AWS).                 |\n",
            "| 2    | **11**   | Nasser Al-Khaldi   | **88**  | TensorFlow/PyTorch, CV, Docker/Kubernetes/AWS, production deployment.         | Less NLP/Hugging Face focus; more CV/predictive analytics.           |\n",
            "| 3    | **21**   | Yasmin Al-Jassim   | **82**  | NLP, recommendation systems, Python, AWS/Docker.                             | Lacks Hugging Face, model optimization, and Kubernetes experience.   |\n",
            "| 4    | **15**   | Sultan Al-Fahim    | **70**  | MLOps (Kubernetes, Kubeflow, CI/CD), AWS/Azure.                              | No direct ML model development (focused on infrastructure).          |\n",
            "| 5    | **29**   | Faisal Al-Qahtani  | **65**  | MLOps (Kubernetes, Terraform, CI/CD), AWS.                                   | No ML model development; purely infrastructure/DevOps.               |\n",
            "\n",
            "---\n",
            "\n",
            "### **Detailed Reasoning**\n",
            "\n",
            "#### **1. Ahmed Al-Otaibi (95/100) ‚Äì *Top Candidate***\n",
            "**Why?**\n",
            "- **Perfect match** for core requirements:\n",
            "  - Python + PyTorch/TensorFlow + Hugging Face (NLP project with AraBERT).\n",
            "  - Production deployment (Docker, FastAPI, AWS) with **quantization** (model optimization).\n",
            "  - **Recommendation systems** (nice-to-have) and **Computer Vision** (YOLOv8).\n",
            "- **Strong problem-solving**: Improved API latency by 40% and reduced false positives by 20%.\n",
            "- **Teamwork**: Collaborated on recommendation engines and demand forecasting.\n",
            "- **Minor gap**: Kubernetes is listed but not emphasized (though Docker/AWS cover deployment).\n",
            "\n",
            "**Standout Projects**:\n",
            "- Arabic Sentiment Analysis (Hugging Face + NLP).\n",
            "- Defect Detection (Computer Vision + YOLOv8).\n",
            "- Recommendation Engine (15% user engagement boost).\n",
            "\n",
            "---\n",
            "\n",
            "#### **2. Nasser Al-Khaldi (88/100) ‚Äì *Strong Contender***\n",
            "**Why?**\n",
            "- **Strong technical fit**:\n",
            "  - PyTorch/TensorFlow, Docker/Kubernetes/AWS, and **production deployment** (edge devices with TensorFlow Lite).\n",
            "  - **Computer Vision** (99.5% accuracy in defect detection) and predictive analytics.\n",
            "- **Industry experience**: Worked at Saudi Aramco (ML for predictive maintenance) and SABIC (manufacturing optimization).\n",
            "- **Gaps**:\n",
            "  - No explicit mention of **Hugging Face** or NLP (focus is CV/predictive analytics).\n",
            "  - Less emphasis on **model optimization** (quantization/pruning).\n",
            "\n",
            "**Standout Projects**:\n",
            "- Automated Quality Control (99.5% accuracy).\n",
            "- Customer Churn Prediction (15% reduction in churn).\n",
            "\n",
            "---\n",
            "\n",
            "#### **3. Yasmin Al-Jassim (82/100) ‚Äì *Good Fit for NLP/Recommendations***\n",
            "**Why?**\n",
            "- **NLP specialization**: Built an Arabic chatbot (Rasa) and a **recommendation system** (nice-to-have).\n",
            "- **Python + AWS/Docker** for deployment.\n",
            "- **Team collaboration**: Worked with marketing teams on personalized offers.\n",
            "- **Gaps**:\n",
            "  - No **Hugging Face** or **model optimization** (quantization/pruning).\n",
            "  - No **Kubernetes** experience (only Docker/AWS).\n",
            "  - Less focus on **Computer Vision**.\n",
            "\n",
            "**Standout Projects**:\n",
            "- Arabic Chatbot (50% faster response time).\n",
            "- News Recommender (18% higher CTR).\n",
            "\n",
            "---\n",
            "\n",
            "#### **4. Sultan Al-Fahim (70/100) ‚Äì *MLOps Specialist***\n",
            "**Why?**\n",
            "- **MLOps expertise**: Kubernetes, Kubeflow, CI/CD (Jenkins, GitLab), AWS/Azure.\n",
            "- **Production experience**: Built pipelines for model monitoring and deployment.\n",
            "- **Gaps**:\n",
            "  - **No direct ML model development** (focused on infrastructure).\n",
            "  - No mention of **Python ML frameworks** (PyTorch/TensorFlow) or **NLP/CV**.\n",
            "  - **Not a fit for the core AI Engineer role** (better suited for MLOps).\n",
            "\n",
            "**Standout Projects**:\n",
            "- CI/CD Pipeline (reduced deployment time from weeks to days).\n",
            "- Model Monitoring System (alerts for drift).\n",
            "\n",
            "---\n",
            "\n",
            "#### **5. Faisal Al-Qahtani (65/100) ‚Äì *MLOps/DevOps Engineer***\n",
            "**Why?**\n",
            "- **Infrastructure focus**: Kubernetes, Terraform, CI/CD (GitHub Actions), AWS.\n",
            "- **Production experience**: Automated model retraining pipelines (Kubeflow).\n",
            "- **Gaps**:\n",
            "  - **No ML model development** (purely DevOps/MLOps).\n",
            "  - No **Python ML frameworks** or **NLP/CV**.\n",
            "  - **Not a fit for the AI Engineer role** (better for MLOps/DevOps).\n",
            "\n",
            "**Standout Projects**:\n",
            "- Automated Model Retraining Pipeline (Kubeflow).\n",
            "- Serving ML Models at Scale (Seldon Core + Kubernetes).\n",
            "\n",
            "---\n",
            "\n",
            "### **Top 3 Candidates**\n",
            "1. **Ahmed Al-Otaibi (95/100)**\n",
            "   - **Best overall fit**: Covers all core requirements + nice-to-haves (recommendation systems, model optimization).\n",
            "   - **Strongest projects**: NLP (Hugging Face), CV (YOLOv8), and production deployment.\n",
            "\n",
            "2. **Nasser Al-Khaldi (88/100)**\n",
            "   - **Strong alternative**: Excellent CV/predictive analytics experience and production deployment.\n",
            "   - **Industry credibility**: Worked at Saudi Aramco and SABIC.\n",
            "\n",
            "3. **Yasmin Al-Jassim (82/100)**\n",
            "   - **Best for NLP/recommendations**: Unique strength in Arabic NLP and recommendation systems.\n",
            "   - **Team player**: Collaborated with marketing teams on AI solutions.\n",
            "\n",
            "---\n",
            "\n",
            "### **Recommendations**\n",
            "- **Interview Ahmed first**: He‚Äôs the closest match and has quantifiable impact (e.g., 40% latency improvement).\n",
            "- **Consider Nasser for CV-heavy roles**: If Computer Vision is a priority, he‚Äôs a strong second choice.\n",
            "- **Yasmin for NLP/recommendation roles**: If the team needs Arabic NLP or recommendation systems, she‚Äôs a great fit.\n",
            "- **Sultan/Faisal for MLOps roles**: If the team needs infrastructure support, these candidates are better suited for MLOps positions.\n"
          ]
        }
      ],
      "source": [
        "# Get Mistral's re-ranking\n",
        "rerank_response = client.chat.complete(\n",
        "    model=\"mistral-large-latest\",\n",
        "    max_tokens=2048,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": rerank_prompt}\n",
        "    ]\n",
        ")\n",
        "\n",
        "rerank_result = rerank_response.choices[0].message.content\n",
        "print(rerank_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cc39ede",
      "metadata": {},
      "source": [
        "### Display Final Ranked Results\n",
        "\n",
        "Let's display Mistral's final ranking and scores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "5c8d5613",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Here‚Äôs the ranked evaluation of the CVs based on the **AI Engineer** job description, with scores (0-100), reasoning, and highlights for the top 3 candidates:\n",
              "\n",
              "---\n",
              "\n",
              "### **Ranking & Scores**\n",
              "| Rank | CV       | Name               | Score | Key Strengths                                                                 | Gaps                                                                 |\n",
              "|------|----------|--------------------|-------|-------------------------------------------------------------------------------|----------------------------------------------------------------------|\n",
              "| 1    | **01_en**| Ahmed Al-Otaibi    | **95**  | Strong Python, PyTorch/TensorFlow, NLP/CV, Hugging Face, Docker/FastAPI/AWS, model optimization, recommendation systems. | Limited Kubernetes experience (but has Docker/AWS).                 |\n",
              "| 2    | **11**   | Nasser Al-Khaldi   | **88**  | TensorFlow/PyTorch, CV, Docker/Kubernetes/AWS, production deployment.         | Less NLP/Hugging Face focus; more CV/predictive analytics.           |\n",
              "| 3    | **21**   | Yasmin Al-Jassim   | **82**  | NLP, recommendation systems, Python, AWS/Docker.                             | Lacks Hugging Face, model optimization, and Kubernetes experience.   |\n",
              "| 4    | **15**   | Sultan Al-Fahim    | **70**  | MLOps (Kubernetes, Kubeflow, CI/CD), AWS/Azure.                              | No direct ML model development (focused on infrastructure).          |\n",
              "| 5    | **29**   | Faisal Al-Qahtani  | **65**  | MLOps (Kubernetes, Terraform, CI/CD), AWS.                                   | No ML model development; purely infrastructure/DevOps.               |\n",
              "\n",
              "---\n",
              "\n",
              "### **Detailed Reasoning**\n",
              "\n",
              "#### **1. Ahmed Al-Otaibi (95/100) ‚Äì *Top Candidate***\n",
              "**Why?**\n",
              "- **Perfect match** for core requirements:\n",
              "  - Python + PyTorch/TensorFlow + Hugging Face (NLP project with AraBERT).\n",
              "  - Production deployment (Docker, FastAPI, AWS) with **quantization** (model optimization).\n",
              "  - **Recommendation systems** (nice-to-have) and **Computer Vision** (YOLOv8).\n",
              "- **Strong problem-solving**: Improved API latency by 40% and reduced false positives by 20%.\n",
              "- **Teamwork**: Collaborated on recommendation engines and demand forecasting.\n",
              "- **Minor gap**: Kubernetes is listed but not emphasized (though Docker/AWS cover deployment).\n",
              "\n",
              "**Standout Projects**:\n",
              "- Arabic Sentiment Analysis (Hugging Face + NLP).\n",
              "- Defect Detection (Computer Vision + YOLOv8).\n",
              "- Recommendation Engine (15% user engagement boost).\n",
              "\n",
              "---\n",
              "\n",
              "#### **2. Nasser Al-Khaldi (88/100) ‚Äì *Strong Contender***\n",
              "**Why?**\n",
              "- **Strong technical fit**:\n",
              "  - PyTorch/TensorFlow, Docker/Kubernetes/AWS, and **production deployment** (edge devices with TensorFlow Lite).\n",
              "  - **Computer Vision** (99.5% accuracy in defect detection) and predictive analytics.\n",
              "- **Industry experience**: Worked at Saudi Aramco (ML for predictive maintenance) and SABIC (manufacturing optimization).\n",
              "- **Gaps**:\n",
              "  - No explicit mention of **Hugging Face** or NLP (focus is CV/predictive analytics).\n",
              "  - Less emphasis on **model optimization** (quantization/pruning).\n",
              "\n",
              "**Standout Projects**:\n",
              "- Automated Quality Control (99.5% accuracy).\n",
              "- Customer Churn Prediction (15% reduction in churn).\n",
              "\n",
              "---\n",
              "\n",
              "#### **3. Yasmin Al-Jassim (82/100) ‚Äì *Good Fit for NLP/Recommendations***\n",
              "**Why?**\n",
              "- **NLP specialization**: Built an Arabic chatbot (Rasa) and a **recommendation system** (nice-to-have).\n",
              "- **Python + AWS/Docker** for deployment.\n",
              "- **Team collaboration**: Worked with marketing teams on personalized offers.\n",
              "- **Gaps**:\n",
              "  - No **Hugging Face** or **model optimization** (quantization/pruning).\n",
              "  - No **Kubernetes** experience (only Docker/AWS).\n",
              "  - Less focus on **Computer Vision**.\n",
              "\n",
              "**Standout Projects**:\n",
              "- Arabic Chatbot (50% faster response time).\n",
              "- News Recommender (18% higher CTR).\n",
              "\n",
              "---\n",
              "\n",
              "#### **4. Sultan Al-Fahim (70/100) ‚Äì *MLOps Specialist***\n",
              "**Why?**\n",
              "- **MLOps expertise**: Kubernetes, Kubeflow, CI/CD (Jenkins, GitLab), AWS/Azure.\n",
              "- **Production experience**: Built pipelines for model monitoring and deployment.\n",
              "- **Gaps**:\n",
              "  - **No direct ML model development** (focused on infrastructure).\n",
              "  - No mention of **Python ML frameworks** (PyTorch/TensorFlow) or **NLP/CV**.\n",
              "  - **Not a fit for the core AI Engineer role** (better suited for MLOps).\n",
              "\n",
              "**Standout Projects**:\n",
              "- CI/CD Pipeline (reduced deployment time from weeks to days).\n",
              "- Model Monitoring System (alerts for drift).\n",
              "\n",
              "---\n",
              "\n",
              "#### **5. Faisal Al-Qahtani (65/100) ‚Äì *MLOps/DevOps Engineer***\n",
              "**Why?**\n",
              "- **Infrastructure focus**: Kubernetes, Terraform, CI/CD (GitHub Actions), AWS.\n",
              "- **Production experience**: Automated model retraining pipelines (Kubeflow).\n",
              "- **Gaps**:\n",
              "  - **No ML model development** (purely DevOps/MLOps).\n",
              "  - No **Python ML frameworks** or **NLP/CV**.\n",
              "  - **Not a fit for the AI Engineer role** (better for MLOps/DevOps).\n",
              "\n",
              "**Standout Projects**:\n",
              "- Automated Model Retraining Pipeline (Kubeflow).\n",
              "- Serving ML Models at Scale (Seldon Core + Kubernetes).\n",
              "\n",
              "---\n",
              "\n",
              "### **Top 3 Candidates**\n",
              "1. **Ahmed Al-Otaibi (95/100)**\n",
              "   - **Best overall fit**: Covers all core requirements + nice-to-haves (recommendation systems, model optimization).\n",
              "   - **Strongest projects**: NLP (Hugging Face), CV (YOLOv8), and production deployment.\n",
              "\n",
              "2. **Nasser Al-Khaldi (88/100)**\n",
              "   - **Strong alternative**: Excellent CV/predictive analytics experience and production deployment.\n",
              "   - **Industry credibility**: Worked at Saudi Aramco and SABIC.\n",
              "\n",
              "3. **Yasmin Al-Jassim (82/100)**\n",
              "   - **Best for NLP/recommendations**: Unique strength in Arabic NLP and recommendation systems.\n",
              "   - **Team player**: Collaborated with marketing teams on AI solutions.\n",
              "\n",
              "---\n",
              "\n",
              "### **Recommendations**\n",
              "- **Interview Ahmed first**: He‚Äôs the closest match and has quantifiable impact (e.g., 40% latency improvement).\n",
              "- **Consider Nasser for CV-heavy roles**: If Computer Vision is a priority, he‚Äôs a strong second choice.\n",
              "- **Yasmin for NLP/recommendation roles**: If the team needs Arabic NLP or recommendation systems, she‚Äôs a great fit.\n",
              "- **Sultan/Faisal for MLOps roles**: If the team needs infrastructure support, these candidates are better suited for MLOps positions."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display formatted results\n",
        "display(Markdown(rerank_result))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c43b31ee",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, we've learned:\n",
        "\n",
        "1. **Basic Mistral AI SDK Usage**: How to initialize the client and make simple API calls\n",
        "2. **CV Scoring**: How to use Mistral to evaluate a single CV against a job description\n",
        "3. **RAG-Based Retrieval**: How to combine:\n",
        "   - **FAISS + sentence-transformers**: Fast vector similarity search across multiple CVs\n",
        "   - **Mistral API**: Intelligent re-ranking and detailed scoring of top candidates\n",
        "\n",
        "This hybrid approach gives you the best of both worlds: speed from vector search and intelligence from Mistral's reasoning capabilities."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
