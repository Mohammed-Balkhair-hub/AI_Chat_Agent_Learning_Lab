{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cd8842f9",
      "metadata": {},
      "source": [
        "# Claude SDK - Learning Notebook\n",
        "\n",
        "This tutorial introduces you to working with the Claude API using the Anthropic SDK, progressing from simple API calls to building a CV scoring and retrieval system.\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this tutorial, you will be able to:\n",
        "- Use the Claude API to generate content\n",
        "- Build a CV scoring system that evaluates resumes against job descriptions\n",
        "- Implement RAG-based CV retrieval using vector similarity search\n",
        "- Combine fast retrieval (FAISS) with intelligent re-ranking (Claude)\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Before starting, make sure you have:\n",
        "- Obtained an Anthropic API key from [Anthropic Console](https://console.anthropic.com/)\n",
        "- Installed the required dependencies listed in `pyproject.toml` via `uv sync`\n",
        "- Set up your `.env` file with `ANTHROPIC_API_KEY=your_key_here`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ac6fe03",
      "metadata": {},
      "source": [
        "## Part 1: Getting Started with Claude SDK"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd941f5d",
      "metadata": {},
      "source": [
        "### Import the SDK and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "858854e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "from anthropic import Anthropic\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86022c4b",
      "metadata": {},
      "source": [
        "### Initialize the Claude Client\n",
        "\n",
        "The Anthropic SDK uses a `Client` object to make requests. The client handles authentication using your API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7eaeb9b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the Claude client\n",
        "api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"ANTHROPIC_API_KEY not found in environment. Please set it in .env file.\")\n",
        "\n",
        "client = Anthropic(api_key=api_key)\n",
        "print(\"Claude client initialized successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f337becc",
      "metadata": {},
      "source": [
        "### Run Your First Prompt\n",
        "\n",
        "Let's start with a simple text generation request. The `claude-3-5-sonnet-20241022` model is Claude's most capable model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "799834c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple text generation\n",
        "message = client.messages.create(\n",
        "    model=\"claude-3-5-sonnet-20241022\",\n",
        "    max_tokens=1024,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Explain AI to me like I'm a kid.\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(message.content[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a27352ea",
      "metadata": {},
      "source": [
        "The response can be rendered directly as markdown in notebooks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cfc1abb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display as markdown\n",
        "display(Markdown(message.content[0].text))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8823e1a",
      "metadata": {},
      "source": [
        "### Start a Chat Conversation\n",
        "\n",
        "Claude supports multi-turn conversations where the conversation history is maintained. Each message includes the full conversation context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a0e75cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start a conversation\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Hello! My name is Alex.\"}\n",
        "]\n",
        "\n",
        "response = client.messages.create(\n",
        "    model=\"claude-3-5-sonnet-20241022\",\n",
        "    max_tokens=1024,\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "print(response.content[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4bbd95b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Continue the conversation - add previous messages to maintain context\n",
        "messages.append({\"role\": \"assistant\", \"content\": response.content[0].text})\n",
        "messages.append({\"role\": \"user\", \"content\": \"What is my name?\"})\n",
        "\n",
        "response = client.messages.create(\n",
        "    model=\"claude-3-5-sonnet-20241022\",\n",
        "    max_tokens=1024,\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "print(response.content[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20181a86",
      "metadata": {},
      "source": [
        "### Control Generation Parameters\n",
        "\n",
        "You can control the model's behavior using parameters like `temperature` and `max_tokens`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51ce9cb0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example with different parameters\n",
        "response = client.messages.create(\n",
        "    model=\"claude-3-5-sonnet-20241022\",\n",
        "    max_tokens=500,  # Limit response length\n",
        "    temperature=0.7,  # Control randomness (0.0 = deterministic, 1.0 = creative)\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Write a short haiku about programming.\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.content[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c0d14d5",
      "metadata": {},
      "source": [
        "## Part 2: CV Scoring Project\n",
        "\n",
        "In this section, we'll build a system that scores a CV against a job description using Claude's reasoning capabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7558156a",
      "metadata": {},
      "source": [
        "### Load a Sample CV\n",
        "\n",
        "Let's load a CV from the CVs folder to use for scoring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cfb9345",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load a sample CV\n",
        "cv_path = \"../CVs/Topic_1/01_en.md\"\n",
        "\n",
        "with open(cv_path, 'r', encoding='utf-8') as f:\n",
        "    cv_content = f.read()\n",
        "\n",
        "print(f\"CV loaded: {len(cv_content)} characters\")\n",
        "print(\"\\nFirst 500 characters:\")\n",
        "print(cv_content[:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10d7a966",
      "metadata": {},
      "source": [
        "### Define a Job Description\n",
        "\n",
        "Create a sample job description to score the CV against."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18543bae",
      "metadata": {},
      "outputs": [],
      "source": [
        "job_description = \"\"\"\n",
        "AI Engineer Position\n",
        "\n",
        "We are looking for an experienced AI Engineer to join our team.\n",
        "\n",
        "Requirements:\n",
        "- Strong experience with Python and machine learning frameworks (PyTorch, TensorFlow)\n",
        "- Experience deploying ML models to production (Docker, FastAPI, AWS)\n",
        "- Background in NLP or Computer Vision\n",
        "- Experience with Hugging Face transformers\n",
        "- Strong problem-solving skills and ability to work in a team\n",
        "\n",
        "Nice to have:\n",
        "- Experience with Kubernetes\n",
        "- Knowledge of model optimization techniques (quantization, pruning)\n",
        "- Experience with recommendation systems\n",
        "\"\"\"\n",
        "\n",
        "print(job_description)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61f0f05e",
      "metadata": {},
      "source": [
        "### Create Scoring Prompt\n",
        "\n",
        "Build a prompt that asks Claude to score the CV against the job description and provide detailed reasoning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e51fd7f",
      "metadata": {},
      "outputs": [],
      "source": [
        "scoring_prompt = f\"\"\"You are an expert recruiter evaluating a CV against a job description.\n",
        "\n",
        "Job Description:\n",
        "{job_description}\n",
        "\n",
        "CV:\n",
        "{cv_content}\n",
        "\n",
        "Please evaluate this CV and provide:\n",
        "1. An overall match score from 0-100\n",
        "2. Detailed reasoning for the score\n",
        "3. Key strengths that match the job requirements\n",
        "4. Areas where the candidate falls short\n",
        "5. Specific examples from the CV that support your evaluation\n",
        "\n",
        "Format your response as a structured evaluation.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07943f49",
      "metadata": {},
      "source": [
        "### Call Claude API to Score the CV\n",
        "\n",
        "Now let's send the prompt to Claude and get the scoring results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28215307",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get scoring from Claude\n",
        "response = client.messages.create(\n",
        "    model=\"claude-3-5-sonnet-20241022\",\n",
        "    max_tokens=2048,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": scoring_prompt}\n",
        "    ]\n",
        ")\n",
        "\n",
        "scoring_result = response.content[0].text\n",
        "print(scoring_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc6c0a10",
      "metadata": {},
      "source": [
        "### Display Results as Markdown\n",
        "\n",
        "Let's render the scoring results nicely:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e6419e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display formatted results\n",
        "display(Markdown(scoring_result))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efebac95",
      "metadata": {},
      "source": [
        "### Extract Structured Output (Optional)\n",
        "\n",
        "If you want to extract specific information like the score, you can parse the response or use Claude's structured output features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cdf594b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple extraction of score (if mentioned in response)\n",
        "import re\n",
        "\n",
        "# Try to extract score from the response\n",
        "score_match = re.search(r'(\\d+)\\s*(?:out of 100|/100|%)', scoring_result, re.IGNORECASE)\n",
        "if score_match:\n",
        "    extracted_score = score_match.group(1)\n",
        "    print(f\"Extracted Score: {extracted_score}/100\")\n",
        "else:\n",
        "    print(\"Score not found in expected format. Check the full response above.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c763d004",
      "metadata": {},
      "source": [
        "## Part 3: RAG-Based CV Retrieval\n",
        "\n",
        "In this section, we'll build a RAG (Retrieval-Augmented Generation) system that:\n",
        "1. Uses FAISS for fast similarity search across multiple CVs\n",
        "2. Uses Claude for intelligent re-ranking and scoring\n",
        "\n",
        "**Hybrid Approach:** We combine the speed of vector similarity search (FAISS) with Claude's reasoning capabilities for the best of both worlds."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f785eb72",
      "metadata": {},
      "source": [
        "### Load All CV Files\n",
        "\n",
        "First, let's load all CV markdown files from the CVs folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "466f5a1e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "from pathlib import Path\n",
        "\n",
        "# Find all markdown CV files\n",
        "cv_base_path = Path(\"../CVs\")\n",
        "cv_files = list(cv_base_path.rglob(\"*.md\"))\n",
        "\n",
        "print(f\"Found {len(cv_files)} CV files\")\n",
        "\n",
        "# Load all CVs\n",
        "cv_data = []\n",
        "for cv_file in cv_files:\n",
        "    with open(cv_file, 'r', encoding='utf-8') as f:\n",
        "        content = f.read()\n",
        "        cv_data.append({\n",
        "            'path': str(cv_file),\n",
        "            'name': cv_file.stem,\n",
        "            'content': content\n",
        "        })\n",
        "\n",
        "print(f\"\\nLoaded {len(cv_data)} CVs\")\n",
        "print(f\"Sample CV names: {[cv['name'] for cv in cv_data[:5]]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7668f0c5",
      "metadata": {},
      "source": [
        "### Initialize Sentence Transformer Model\n",
        "\n",
        "**Important:** Despite the name \"sentence-transformers\", this library works with full documents! It processes entire CVs (even 1000+ words) and produces a single fixed-size embedding vector (e.g., 384 dimensions) that captures the semantic meaning of the whole document. This is standard practice for document similarity tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acd3189b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Initialize the model - works with full documents, not just sentences\n",
        "# This model produces 384-dimensional embeddings\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "print(\"Sentence transformer model loaded!\")\n",
        "print(f\"Model will produce embeddings of dimension: {model.get_sentence_embedding_dimension()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "581059d9",
      "metadata": {},
      "source": [
        "### Generate Embeddings for All CVs\n",
        "\n",
        "Each full CV (entire document) will become one embedding vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21a27a2d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract CV texts\n",
        "cv_texts = [cv['content'] for cv in cv_data]\n",
        "\n",
        "# Generate embeddings - each CV becomes one vector\n",
        "# Shape will be (num_cvs, 384) - one 384-dimensional vector per CV\n",
        "print(\"Generating embeddings for all CVs...\")\n",
        "cv_embeddings = model.encode(cv_texts, show_progress_bar=True)\n",
        "\n",
        "print(f\"\\nEmbeddings shape: {cv_embeddings.shape}\")\n",
        "print(f\"Number of CVs: {len(cv_data)}\")\n",
        "print(f\"Embedding dimension: {cv_embeddings.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eb65cb1",
      "metadata": {},
      "source": [
        "### Generate Embedding for Job Description\n",
        "\n",
        "Now let's create an embedding for the job description so we can find similar CVs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d40191e2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate embedding for job description\n",
        "job_embedding = model.encode([job_description])\n",
        "\n",
        "print(f\"Job description embedding shape: {job_embedding.shape}\")\n",
        "print(\"Job description embedded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ede69383",
      "metadata": {},
      "outputs": [],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Get the dimension of embeddings\n",
        "dimension = cv_embeddings.shape[1]\n",
        "\n",
        "# Create FAISS index using L2 (Euclidean) distance\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "# Convert to float32 (required by FAISS) and add embeddings\n",
        "index.add(cv_embeddings.astype('float32'))\n",
        "\n",
        "print(f\"FAISS index created with {index.ntotal} CVs\")\n",
        "print(f\"Index dimension: {dimension}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "732b8479",
      "metadata": {},
      "source": [
        "### Search for Top-K Most Relevant CVs\n",
        "\n",
        "Now let's search for the CVs most similar to the job description using FAISS."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d6c6e1b",
      "metadata": {},
      "source": [
        "### Display Retrieved CVs with Similarity Scores\n",
        "\n",
        "Let's see which CVs were retrieved and their similarity scores."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37762b4f",
      "metadata": {},
      "source": [
        "### Use Claude to Re-rank and Score Top Candidates\n",
        "\n",
        "Now let's use Claude's reasoning capabilities to intelligently re-rank and score the top candidates. This combines fast retrieval (FAISS) with intelligent evaluation (Claude)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad6cb9e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get Claude's re-ranking\n",
        "rerank_response = client.messages.create(\n",
        "    model=\"claude-3-5-sonnet-20241022\",\n",
        "    max_tokens=2048,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": rerank_prompt}\n",
        "    ]\n",
        ")\n",
        "\n",
        "rerank_result = rerank_response.content[0].text\n",
        "print(rerank_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9019021",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display formatted results\n",
        "display(Markdown(rerank_result))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae39f8aa",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, we've learned:\n",
        "\n",
        "1. **Basic Claude SDK Usage**: How to initialize the client and make simple API calls\n",
        "2. **CV Scoring**: How to use Claude to evaluate a single CV against a job description\n",
        "3. **RAG-Based Retrieval**: How to combine:\n",
        "   - **FAISS + sentence-transformers**: Fast vector similarity search across multiple CVs\n",
        "   - **Claude API**: Intelligent re-ranking and detailed scoring of top candidates\n",
        "\n",
        "This hybrid approach gives you the best of both worlds: speed from vector search and intelligence from Claude's reasoning capabilities."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
